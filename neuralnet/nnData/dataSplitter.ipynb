{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9478c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a62d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitSize = 80000\n",
    "filePath = '/Users/aly/Desktop/Main/funni_code/mldata/sentimentData.csv'\n",
    "\n",
    "\n",
    "for i, split in enumerate(pd.read_csv(filePath, chunksize = splitSize, encoding='ISO-8859-1')):\n",
    "    split.to_csv(f'testSplit{i}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd503fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit0.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit1.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit2.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit3.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit4.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit5.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit6.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit7.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit8.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit9.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit10.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit11.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit12.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit13.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit14.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit15.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit16.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit17.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit18.csv: ['NO_QUERY']\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit19.csv: ['NO_QUERY']\n"
     ]
    }
   ],
   "source": [
    "filePath = '/Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/'\n",
    "filePrefix = 'testSplit'\n",
    "fileCount = 20\n",
    "\n",
    "for i in range(fileCount):\n",
    "    fileName = f'{filePath}{filePrefix}{i}.csv'\n",
    "    if os.path.exists(fileName):\n",
    "        df = pd.read_csv(fileName, encoding = 'ISO-8859-1')\n",
    "        \n",
    "        if df.shape[1] >= 3:\n",
    "            uniqueVal = df.iloc[:,3].unique()\n",
    "            print(f'uniques - {fileName}: {uniqueVal}')\n",
    "        else:\n",
    "            print(f'{fileName} has <3 col')\n",
    "    else:\n",
    "        print(f'{fileName} DNE')\n",
    "\n",
    "##we know from this that all the files exist and that the loop works as intended\n",
    "##therefore, we don't need any more else statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72150121",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = '/Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/'\n",
    "filePrefix = 'testSplit'\n",
    "fileCount = 20\n",
    "\n",
    "for i in range(fileCount):\n",
    "    fileName = f'{filePath}{filePrefix}{i}.csv'\n",
    "    df = pd.read_csv(fileName, encoding = 'ISO-8859-1')\n",
    "    df = df.iloc[:,[0,5]]\n",
    "    df.to_csv(fileName, index = False)\n",
    "    \n",
    "##clearing out all the extraneous columns (indices 1-4)\n",
    "##keeping [TARGET] and [MESSAGE] columns only :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76725319",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now we need to replace all @ mentions in all files with generic \"@user\" for\n",
    "##the sake of efficiency\n",
    "\n",
    "filePath = '/Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/'\n",
    "filePrefix = 'testSplit'\n",
    "fileCount = 20\n",
    "\n",
    "for i in range(fileCount):\n",
    "    fileName = f'{filePath}{filePrefix}{i}.csv'\n",
    "    df = pd.read_csv(fileName, encoding = 'ISO-8859-1')\n",
    "    ##define @username pattern\n",
    "    userPattern = r'@\\w+'\n",
    "    df.iloc[:,1] = df.iloc[:,1].str.replace(userPattern, '@user', regex = True)\n",
    "    df.to_csv(fileName, index = False)\n",
    "    \n",
    "##all files should be ready to go..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc5db2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now we will be removing all urls and encoding errors:\n",
    "\n",
    "def clean(line):\n",
    "    line = html.unescape(line)\n",
    "    line = re.sub(r'[^\\x00-\\x7F]+', ' ', line)\n",
    "    line = re.sub(r'http\\S+|www\\S+|https\\S+', '', line, flags = re.MULTILINE)\n",
    "    return line\n",
    "\n",
    "filePath = '/Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/'\n",
    "filePrefix = 'testSplit'\n",
    "fileCount = 20\n",
    "\n",
    "for i in range(fileCount):\n",
    "    fileName = f'{filePath}{filePrefix}{i}.csv'\n",
    "    df = pd.read_csv(fileName, encoding = 'ISO-8859-1')\n",
    "    df.iloc[:,1] = df.iloc[:,1].apply(clean)\n",
    "    df.to_csv(fileName, index = False)\n",
    "    \n",
    "##done yayyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "442e3319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit0.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit1.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit2.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit3.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit4.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit5.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit6.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit7.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit8.csv: [0]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit9.csv: [0 4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit10.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit11.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit12.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit13.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit14.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit15.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit16.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit17.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit18.csv: [4]\n",
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit19.csv: [4]\n"
     ]
    }
   ],
   "source": [
    "##checking if neutral (value of 2 in col index 0) exists\n",
    "filePath = '/Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/'\n",
    "filePrefix = 'testSplit'\n",
    "fileCount = 20\n",
    "\n",
    "for i in range(fileCount):\n",
    "    fileName = f'{filePath}{filePrefix}{i}.csv'\n",
    "    df = pd.read_csv(fileName, encoding = 'ISO-8859-1')\n",
    "    uniqueVal = df.iloc[:,0].unique()\n",
    "    print(f'uniques - {fileName}: {uniqueVal}')\n",
    "    \n",
    "##we know from this that all the files exist and that the loop works as intended\n",
    "##therefore, we don't need any more else statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90ea2a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniques - /Users/aly/Desktop/Main/funni_code/machinelearning/neuralnet/nnData/testSplit19.csv: [0 4]\n"
     ]
    }
   ],
   "source": [
    "##checking source file for uniques\n",
    "\n",
    "filePath = '/Users/aly/Desktop/Main/funni_code/mldata/sentimentData.csv'\n",
    "df = pd.read_csv(filePath, encoding = 'ISO-8859-1')\n",
    "uniqueVal = df.iloc[:,0].unique()\n",
    "print(f'uniques - {fileName}: {uniqueVal}')\n",
    "\n",
    "##as 2 (neutral) doesnt exist in my cleaned data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
